S3 Overall concepts
	S3 is Object based i.e. it allows you to upload files




Helpful Commands
	aws s3 sync --recursive /var/www/html/ s3://BUCKET_NAME
		You want to sync the changes between an EC2 directory and an S3 bucket

		You can always run this as a cron job, etc.
			If you change /etc/crontab
				service crond restart

		If you are syncing all of your HTML files up to an S3 bucket every 2 mins AND you have multiple failover nodes
			Have a seperate cron job every 3 minutes that will pull any changes back down to your local directory (from S3).

			This is great if any other node made changes to the s3 bucket

		After you've set up all of these commands, it would be smart to create an AMI snapshot and then utilize that as your "base"

	aws s3 cp --recursive EC2_DIR s3://BUCKET_NAME


Use cases
	File sharing
	Backup
		Compare/Contrast with Glacier
	Origin for CloudFront CDN
	Hosting Static Websites 

Files
	Multipart uploads so you can upload parts of a file concurrently
		Should do this for files 100Mb or over.
		Is a requirement for any file over 5Gbs

	Allows for uploads to resumed after a stop

	Can have metadata (key/val) pairs on each file

	Can be from 1 Byte to 5Tb

	There is unlimited storage 

	Allows encryption

	Stored in Buckets (like a directory)
		Difference between a bucket and a directory
			Buckets have a unique namespace for each region (thus two buckets in the same region can't have the same name)



Standard S3
	99.99% availability
	99.999999999% durability	

	Guarentees 99.99% availability for the S3 platform
		Eventual consistency over multiple availability zones
			AWS does this automatically on a per region basis
			All AZ's that s3 files will be spread to will eventually be consistent.
				Put/Write/Delete, etc. requests will eventually be consistent.
				Eventually consistency = Not instantaneous

	Guarantees 99.999999999% durability for S3 information
		This has to do with the storage of files

Reduced Redundancy Storage
	Same at "Standard s3" but with 99.99% durability
		In general, it is recommended NOT to do this unless the files aren't really important  
			Do the benefits outweigh the costs?

Versioning
	Stores all versions of an s3 file (including all writes and even if ou delete an object)
	Once set up, versioning can't be disabled, only suspended.

	Remember that you might already be doing version control in another place, so this might not always be necessary

Licecycle Management
	Can be used in conjunction with versioning
	Can be applied to current versions and previous versions

	You can use these actions in conjunction with versioning (or without)
		Archive Only
		Permanently Delete Only
		Archive and then permanently delete

Encryption
	Encryption Type
		Advanced Encryption Standard (AES) 256 Encryption
			Know what AES stands for

	Encryption can be either Server Side or Client Side
		Server Side
			Amazon S3 Managed Keys - Standard Service

			AWS KMS - Managed Keys
				Currently AT


	Can upload/download your data via SSL
	Files can be automatically encrypted at rest




S3 can be used as an origin for CloudFront's CDN

Access Control
	You can utilize the following ways to manage your keys that give access to S3
		AWS Key Management Service (AWS KMS)
		Native S3 key management
		Provide your own keys

General Security
	All buckets are private by default 
	Allows ACL (Access Control Lists)
		Ex: A user can only have access to his/her bucket and can only have read access
	Can integrate with IAM
		Ex: Can set a role so EC2 users have access to S3 buckets, etc

Static Website hosting
	No need for webservers
		Dont need to worry about traffic management, autoscaling, load balancing, etc.

Integrates with Cloud Front CDN
	Steps
		Create a bucket that will house the files utilized by CloudFront (CDN).  This can contain images, etc


TD: Set up SSL (BR: Privacy)
Integrates with Cloud Front CDN
  TD: Set up CDN, with “Web Delivery method” and S3 origin
Deals with all caching, autoscaling, etc.

